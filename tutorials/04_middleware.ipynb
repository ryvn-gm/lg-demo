{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6890eaa",
   "metadata": {},
   "source": [
    "### 基礎設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104732c",
   "metadata": {},
   "source": [
    "### 模型動態選擇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b4b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "web_search = TavilySearch(max_results=2)\n",
    "tools = [web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc53dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- ① 準備兩種 OpenAI 模型 (一個省錢，一個聰明) ---\n",
    "\n",
    "basic_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "reasoner_model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "def _get_last_user_text(messages) -> str:\n",
    "    \"\"\"\n",
    "    [輔助工具]\n",
    "    從一堆對話紀錄(messages)中，挖出「使用者講的最後一句話」。\n",
    "    (如果找不到，就回傳一個空字串 \"\" )\n",
    "    \"\"\"\n",
    "    # 從後面往前翻 (reversed)\n",
    "    for m in reversed(messages):\n",
    "        # 抓到 HumanMessage (使用者)\n",
    "        if isinstance(m, HumanMessage):\n",
    "            # content 可能是純文字，也可能是 [圖, 文] 這種複雜格式\n",
    "            # 我們這裡只處理最常見的「純文字」情況\n",
    "            return m.content if isinstance(m.content, str) else \"\"\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# 分流器\n",
    "@wrap_model_call\n",
    "def dynamic_openai_routing(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"\n",
    "    (這是一個 LangChain 中間件 Middleware)\n",
    "    \n",
    "    💡 核心邏輯：動態 AI 模型路由！\n",
    "    \n",
    "    根據對話的「複雜度」，自動切換要 call 哪一個 OpenAI 模型。\n",
    "    - 複雜問題 (例如數學、寫程式) -> gpt-4o\n",
    "    - 簡單問題 (例如哈囉、聊天) -> gpt-4o-mini\n",
    "    \"\"\"\n",
    "    \n",
    "    # 先從 request 裡面把完整的對話紀錄(messages)挖出來\n",
    "    messages = request.state.get(\"messages\", [])\n",
    "    msg_count = len(messages) # 總共講了幾句話\n",
    "    \n",
    "    # 抓出使用者最後一句話\n",
    "    last_user = _get_last_user_text(messages)\n",
    "    last_len = len(last_user) # 最後一句話有多長\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 🕵️‍♂️ 判斷「複雜任務」的關鍵詞 (你可以自己多加一點)\n",
    "    # ----------------------------------------------------\n",
    "    hard_keywords = (\n",
    "        \"證明\", \"推導\", \"嚴謹\", \"規劃\", \"多步驟\", \"演算法\", \"優化\",\n",
    "        \"chain of thought\", \"step-by-step\", \"reason step by step\",\n",
    "        \"數學\", \"邏輯證明\", \"約束求解\", \"寫程式\", \"debug\"\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 💡 判斷是否為「困難模式」的 Heuristics\n",
    "    # ----------------------------------------------------\n",
    "    is_hard = (\n",
    "        msg_count > 10 or  # 1. 已經聊很久了 (可能進入深度討論)\n",
    "        last_len > 120 or  # 2. 使用者一口氣問了超長的問題\n",
    "        any(kw.lower() in last_user.lower() for kw in hard_keywords) # 3. 困難關鍵詞\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 🚦 決定要派誰出場！\n",
    "    # ----------------------------------------------------\n",
    "    if is_hard:\n",
    "        # 判定為困難\n",
    "        request.model = reasoner_model\n",
    "    else:\n",
    "        # 只是小問題\n",
    "        request.model = basic_model\n",
    "\n",
    "    # 🚀 把 request (已經被我們偷換掉 model) 丟給下一棒 (handler)\n",
    "    # handler 就是「真正去 call AI」的人\n",
    "    return handler(request)\n",
    "\n",
    "# ② 創建 Agent\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    tools=tools,  \n",
    "    middleware=[dynamic_openai_routing]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22729aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "simple_question = \"請問台北市長是誰？\"\n",
    "simple_response = agent.invoke({\"messages\": [HumanMessage(content=simple_question)]})\n",
    "\n",
    "simple_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_question = \"\"\"\n",
    "請幫我詳細推理以下數學問題：\n",
    "假設有一個粒子以恆定加速度 $$ a $$ 沿著直線運動，初速度為 $$ v_0 $$，位移為 $$ s $$。\n",
    "請推導出其速度和時間 $$ t $$ 之間的函數關係，並且逐步解釋每一個步驟的物理意義義。\n",
    "\"\"\"\n",
    "complex_response = agent.invoke({\"messages\": [HumanMessage(content=complex_question)]})\n",
    "\n",
    "complex_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4d604",
   "metadata": {},
   "source": [
    "### 裁剪訊息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ddde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langchain.messages import RemoveMessage, SystemMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.runtime import Runtime\n",
    "from typing import Any\n",
    "from langchain.tools import tool\n",
    "\n",
    "# --- 1. 初始化 AI 模型 ---\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "# --- 2. 關鍵的「記憶體裁剪」 (Middleware) ---\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"\n",
    "    在把對話紀錄(state)丟給 AI 動腦之前，\n",
    "    我們先在這裡動手腳，把紀錄「砍到」只剩精華。\n",
    "    \n",
    "    為什麼要這麼做？\n",
    "    1. 省錢！ (Token 越少越省錢)\n",
    "    2. 避免 AI 記憶體爆炸 (Context Window)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 先把到目前為止的「完整對話紀錄」(一長串) 拿出來\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 我們的「裁剪規則」：\n",
    "    # 保留「第一則 (人設)」 + 「最後三則 (最新對話)」\n",
    "    # ----------------------------------------------------\n",
    "    KEEP_FIRST = 1 \n",
    "    KEEP_LAST = 3\n",
    "    TOTAL_KEPT = KEEP_FIRST + KEEP_LAST # 總共要留 4 則\n",
    "\n",
    "    # 如果對話還很短 (小於等於 4 句)\n",
    "    if len(messages) <= TOTAL_KEPT:\n",
    "        return None  # 回傳 None 代表「沒事，照常執行」\n",
    "\n",
    "    # --- 開始裁剪！ ---\n",
    "    \n",
    "    # 保留第 0 則訊息 (這 99% 是我們的「系統提示」或「人設」)\n",
    "    first_msg = messages[0] \n",
    "    \n",
    "    # 抓出最後 3 則訊息 (最新的對話)\n",
    "    last_three_msgs = messages[-KEEP_LAST:]\n",
    "\n",
    "    # 組合出我們的重要的對話紀錄\n",
    "    new_messages = [first_msg] + last_three_msgs\n",
    "\n",
    "    print(\n",
    "        f\"\\n✂️ 原 {len(messages)} 則 → 砍到剩 {len(new_messages)} 則\\n\"\n",
    "    )\n",
    "\n",
    "    # 回傳一個字典，告訴 Agent 執行器 (Runtime) 該怎麼更新 state\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            # 1. 先把舊的紀錄「全部洗掉」(一鍵清空)！\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            # 2. 再把我們整理好的訊息塞回去\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# --- 4. 建立 Agent ---\n",
    "agent = create_agent(\n",
    "    model=model,              \n",
    "    tools=tools,                 \n",
    "    middleware=[trim_messages],  \n",
    "    checkpointer=InMemorySaver(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d86150",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"2\"  \n",
    "    }\n",
    "}\n",
    "\n",
    "# 第一次對話\n",
    "agent.invoke(\n",
    "    {\"messages\": \"你是小豬豬\"},\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bb4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": \"給我一句心靈雞湯\"},\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b09811",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\n",
    "    {\"messages\": \"你是誰？\"},\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9eba02",
   "metadata": {},
   "source": [
    "### 練習\n",
    "\n",
    "- Summarization\n",
    "- Human In The Loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
